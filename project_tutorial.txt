;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; CLOUD COMPUTING PROJECT PASSAGES
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; INTRODUCTION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
This file contains a first draft of the project description and of the passages needed to make the project for the course Cloud Computing work on AWS.
Please notice that this version of the passages is tested over a restricted version of the environment (Sandbox Environment of the Cloud Foundations Course) that will later be used for the final version of the project (Learner Lab with credits).
The aim of this file is to describe all the "mechanical" steps that we will later use (independently from the specific decisions we will make about the types of services that we will use) to do the configurations of our system among the AWS services needed.
This passages are tested over a Linux machine so in some points the instruction may change (w.r.t. the OS used; it should be the same for macOS users but different for Windows users)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; PROJECT DESCRIPTION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
The goal of the project is to design and implement a web application and later on test its ability to scale when stressed out by users.
The web application consists in a tool that allow users to upload an image: each image is then processed by a machine learning model.
The model, trained over 100.000 examples of world entities (like airplanes, dogs, cats, trucks...), will identify the correct category of in which the image uploaded by the user belongs.
The web application and the Python script that contains the implementation of the model are two separate parts that interact over a common storage in which the model (after being trained) is stored.


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; DESIGN
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Model Script
The model is an image recognition model trained of the CIFAR-100 and CIFAR-10 datasets.
Specifically the model is at first trained over the CIFAR-100 dataset, a dataset containing 60.000 32x32 images (divded into 100 classes of 600 images each, and specifically of 500 training images and 100 test images each) representing each possible category in which the world entites can be grouped (there are actually 20 superclasses like aquatic mammals, fish, flowers, food containers,... and, for each superclass there are then some classes in which the images can be classified).
The obtained model is then used as the base of the training for our final model that is then trained with the CIFAR-10 dataset which is once again a dataset containing 60.000 32x32 images that are this time divided into 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) of 6.000 images each (5.000 for the training and 1.000 for testing).
The goal for our model is to creat a multiclass classificator used to classify each image provided by the users into one of the 10 classes provided by the CIFAR-10 dataset

2. Web Application
The web application acts as the front-end of our system: it can recieve any picture (of any dimensions or colors) as input and then it will display the prediction produced by our pre-trained model

3. Storage
The strage is the poin of contact of the parts of our system: it's a place in which the trained model is saved by the model training at the end of its task and in which the web application can retrieve the model in order to pass the input and wait for the prediction


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; IMPLEMENTATION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Model Training Task
The implementation of the model has been made thanks to the Tensorflow and Keras library: we decided to use a Sequential Neural Network composed by different layers for recogninition and normalization; later on the first trained model has been used as first layer of our final model

2. Web Application
The framework used for the web application is Streamlit. Streamlit is a Python library used specifically to create web interfaces for machine learning model.
When first launched the application waits for the user to upload an image and then after submitting the input the application do some image pre-processing in order to make the image uploaded works with the model and then waits for the prediction made by the previously downloaded pre-trained model


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; STORAGE DEPLOYMENT
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. AWS S3 configuration
In order to use a bucket in which we will upload the trained model file we must first create it.

The parameters to be configured are the following:
- Name: model-bucket
- Region: us-east-1 (this should be good also into the Learner Lab)
- Access Control Lists: disabled
- Access Settings: enabled through the policy presented later
- Bucket Versioning: enabled to keep multiple version of the same file
- Tags and Encryption: disabled

The bucket must be accessible by the model script in writing mode and by the application in reading mode, so we define the following policy:
                                [POLICY]
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicRead",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject",
                "s3:GetObjectVersion"
            ],
            "Resource": [
                "arn:aws:s3:::<BUCKET-NAME>/*"
            ]
        }
    ]
}
In this way the public access in read mode is permitted to anyone and, since the bucket will contain the trained model (which is not a secret file) there is no need to keep it hidden.

In order to let the bucket be accessible in writing mode by the script we will give the script the access and secret key of an IAM role that has the authorization to write to the S3 Bucket and so we should not enable a specific policy for that

2. FOLLOW THIS STEPS TO CREATE THE BUCKET
- Bucket Name: cloud-computing-model-bucket
- AWS Region: us-east-1
- Copy the settings from an existing bucket: optional (do not do anything and leave it as it is)
- Object Ownerships: check "ACL disabled"
- Block Public Access Settings for this Bucket:
    - Uncheck "Block ALL public access"
    - Check "Block public access to granted buckets and objects using new access control lists (ACLs)"
    - Check "Block public access to granted buckets and objects via any access control list (ACL)"
    - Check "I acknowledge that the current settings may make this bucket and the objects in it public."
- Multiple Version for the Bucket: check "Enable"
- Leave everything else as it is
- Create the Bucket
- From the dashboard:
    - Click on "Bucket"
    - Select the newly created bucket
    - Go on "Authorization"
    - Scroll down up until you find "Bucket Policy"
    - Click on "Modify"
    - Add the policy [POLICY] presented before by substituting the <BUCKET-NAME> with the name you gave to the bucket (you can also directly copy the bucket ARN presented by AWS)
    - Click on "Save Changes"


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; PREPARE THINGS TO WORK
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
0. KEYS TO ACCESS TO EVERYTHING CAN BE FOUND BY CLICKING "AWS Details" IN THE SANDBOX ACCESS PANEL UNDER THE AWS CLI SHOW BUTTON
1. Save the Secret Credentials to .aws/credentials file on your local machine (Remember to repeat this step everytime that the sandbox is started because the token expire)
2. Install AWS CLI (skip if present on local machine:
    - Go to "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html" and follow the instruction for your OS


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; MODEL DEPLOYMENT
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Create a repository in ECR:
    - Go to ECR from the AWS Service Panel
    - Choose "Create Repository"
    - Select "Private" as "Visibility Option" (boh)
    - Choose a name for the repository (e.g. cloud_model)
    - Leave everything else as it is
    - Click on "Create Repository"
2. Push the image to the repository:
    - Go to "Repositories"
    - Select the wanted repository
    - Click on "Show Push Commands"
    - Copy the commands on your local shell where the AWS CLI is running and it's done
3. Create the EC2 instance:
    - From the AWS Service Panel go to EC2
    - Select "Instances"
    - From the dropdown menu "Start Instances" select "Start Instance"
    - Choose an instance name (e.g. Cloud Model)
    - Select "Amazon Linux 2" as AMI
    - Select "t2.large" as instance (not sure, maybe we can try something different when accessing to the true sandbox)
    - Choose the key-value pair "vockey" (default not sure if we can create another one but I don't thik so)
    - As for the "Network Settings" choose the "create a new security group" and leave everything as it is
    - Leave everything else as it is
    - Open "Advanced Details"
    - As for "Instance IAM Profile" choose "LabInstanceProfile"
    - Go to "user data" and add the following script [SCRIPT] to configure Docker on the instance:
                            [SCRIPT]
#!/bin/bash
sudo yum update -y
sudo yum install amazon-linux-extras
sudo amazon-linux-extras install docker -y
sudo service docker start
sudo usermod -a -G docker ec2-user
sudo systemctl enable docker
sudo gpasswd -a ec2-user docker
sudo grpck
sudo grpconv
newgrp docker
groups
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com
docker pull <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>:latest
docker run --rm <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>
                            [END SCRIPT]
    (AWS_ACCOUT_ID Lucia : 131920089270)
    (REPOSITORY_NAME Model : cloud_model)
    - Click on "Start Instance"


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; WEB APPLICATION DEPLOYMENT (SINGLE INSTANCE)
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Create a repository in ECR:
    - Go to ECR from the AWS Service Panel
    - Choose "Create Repository"
    - Select "Private" as "Visibility Option" (boh)
    - Choose a name for the repository (e.g. cloud_webapp)
    - Leave everything else as it is
    - Click on "Create Repository"
2. Push the image to the repository:
    - Go to "Repositories"
    - Select the wanted repository
    - Click on "Show Push Commands"
    - Copy the commands on your local shell where the AWS CLI is running and it's done
3. Create the EC2 instance:
    - From the AWS Service Panel go to EC2
    - Select "Instances"
    - From the dropdown menu "Start Instances" select "Start Instance"
    - Choose an instance name (e.g. Cloud Web App)
    - Select "Amazon Linux 2" as AMI
    - Select "t2.micro" as instance (not sure, maybe we can try something different when accessing to the true sandbox)
    - Choose the key-value pair "vockey" (default not sure if we can create another one but I don't thik so)
    - As for the "Network Settings" choose the "create a new security group"
    - Check the "Allow HTTP traffic from internet"
    - Click on Edit
    - Add a new security rule
    - Choose "Custom TCP"
    - As for the port type "8080"
    - Choose 0.0.0.0/0 to allow traffic from anywhere
    - Leave everything else as it is
    - Open "Advanced Details"
    - As for "Instance IAM Profile" choose "LabInstanceProfile"
    - Go to "user data" and add the following script [SCRIPT] to configure Docker on the instance:
                            [SCRIPT]
#!/bin/bash
sudo yum update -y
sudo yum install amazon-linux-extras
sudo amazon-linux-extras install docker -y
sudo service docker start
sudo usermod -a -G docker ec2-user
sudo systemctl enable docker
sudo gpasswd -a ec2-user docker
sudo grpck
sudo grpconv
newgrp docker
groups
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com
docker pull <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>:latest
docker run -dp 8080:5000 <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>
                            [END SCRIPT]
    (AWS_ACCOUT_ID Lucia : 131920089270)
    (REPOSITORY_NAME Web Application: cloud_webapp)
    - Click on "Start Instance"
    - Wait until the Status Check are passed
    - Now the web application is up and running!
    - To connect to the web application just copy the "Public IP Address" and then add :8080 to connect to the right port


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; AUTOSCALING GROUP
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Create Security Group:
    - From the EC2 dashboard go to "Security Groups"
    - Choose a name for the security group (e.g. autoscaling-security-group)
    - Choose a description for the security group (e.g. autoscaling-security-group)
    - Add the following Inbound rules:
        + Type : Custom TCP
        + Port Range: 8080
        + Source : Anywhere IPv4

        + Type : Custom TCP
        + Port Range : 8080
        + Source : Anywhere IPv6

        + Type : HTTP
        + Port Range : 80
        + Source : Anywhere IPv4

        + Type : SSH
        + Port Range : 22
        + Source : Anywhere IPv4
    - Add the following Outbound rules:
        + Type : All traffic
        + Protocol : All
        + Port Range : All
        + Destination : Custom
    - Click on "Create new security group"
2. Create the Launch Template:
    - From the EC2 dashboard go to "Launch Templates"
    - Click on "Launch Template"
    - Choose a name for the template (e.g. autoscaling-launch-template)
    - Choose a description for the template (e.g. autoscaling-launch-template)
    - Under the "Auto Scaling guidance" click on "Provide guidance to help me set up a template I can use with EC2 Auto Scaling"
    - Under "Application and OS Images" click on "Quick Start" and choose "Amazon Linux 2"
    - Under "Instance type" choose "t2.large"
    - Choose "vockey" as "Key Pair"
    - As for the "Security Group" choose the security group created at point 1.
    - Under "Advanced details" choose the "LabInstanceProfile" as "IAM instance profile"
    - Enable "Deatiled CloudWatch monitoring"
    - Copy the script [SCRIPT] of the section WEB APPLICATION DEPLOYMENT in "User data"
    - Click on "Create launch template"
3. Create the Autoscaling group
    - From the EC2 dashboard go to "Auto Scaling Groups"
    - Click on "Create Auto Scaling group"
    - Choose a name for the Auto Scaling group (e.g. image-recognition-aws)
    - For the "Launch template" choose the template created at point 2.
    - Click "Next"
    - For the "Network" leave the vpc already selected and select all the 6 "Availability Zones and subnets"
    - Click on "Next"
    - As for the "Load balancing" select "Attach to a new load balancer"
    - As for the "Load balancer scheme" select "internet-facing"
    - As for the "Listeners and routing" change the Port to 8080 and select "Create a target group" under the "Default routing"
    - Check "Turn on Elastic Load Balancing Health Checks"
    - Under "Additional Settings" click on "Enable Group Metrics Collection withing CloudWatch"
    - Leave everything else as it is
    - Click on "Next"
    - For the "Group size" use the following configuration:
        + Desired capacity : 1
        + Minimum capacity : 1
        + Maximum capacity : 3 (to be checked if it's okay while doing the stress tests)
    - For the "Scaling policies" select "None"
    - Click on "Next"
    - Clcik on "Next"
    - Click on "Next"
    - Create "Auto Scaling group"
4. Create Alarms for Policy:
    - Go to CloudWatch
    - Go to Alarms -> All alarms -> Create alarm
    - Click on "Select metric"
    - Search for CPU
    - Click EC2 > By Auto Scaling Group
    - Select CPUUtilization (CHECK FOR THE CORRECT AUTOSCALING GROUP NAME)
    - Click on "Select Metric"
    - From "Statistic" select "Average"
    - From "Period" select "1 minute"
    - In the "Conditions" Panel:
        + Threshold Type : Static
        + Whenever CPUUtilization is : Greater (Greater/Equal) or Lower (Lower/Equal)
        + than... : 60
    - Click "Next"
    - Remove the "Notification" settings
    - Leave everything else as it is
    - Give a name to the alarm
    - Click "Next"
    - Click "Create Alarm"
5. Attach alrams to scaling policy:
    - Go to Auto Scaling Groups
    - Click on the wanted Auto Scaling Group
    - Click on "Automatic Scaling"
    - Click on "Create dynamic scaling policy"
    - For "Policy type" select "Simple Scaling"
    - Set a name for the policy
    - Select the wanted CloudWatch alarm
    - Configure the wanted action
    - For "And then wait" put "30" (to be checked)

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; TESTS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

