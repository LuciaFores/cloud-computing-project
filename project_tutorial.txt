;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; CLOUD COMPUTING PROJECT PASSAGES
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; INTRODUCTION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
This file contains a first draft of the project description and of the passages needed to make the project for the course Cloud Computing work on AWS.
Please notice that this version of the passages is tested over a restricted version of the environment (Sandbox Environment of the Cloud Foundations Course) that will later be used for the final version of the project (Learner Lab with credits).
The aim of this file is to describe all the "mechanical" steps that we will later use (independently from the specific decisions we will make about the types of services that we will use) to do the configurations of our system among the AWS services needed.
This passages are tested over a Linux machine so in some points the instruction may change (w.r.t. the OS used; it should be the same for macOS users but different for Windows users)


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; PROJECT DESCRIPTION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
The goal of the project is to design and implement a web application and later on test its ability to scale when stressed out by users.
The web application consists in a tool that allow users to upload an image: each image is then processed by a machine learning model.
The model, trained over 100.000 examples of world entities (like airplanes, dogs, cats, trucks...), will identify the correct category of in which the image uploaded by the user belongs.
The web application and the Python script that contains the implementation of the model are two separate parts that interact over a common storage in which the model (after being trained) is stored.


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; DESIGN
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Model Script
The model is an image recognition model trained of the CIFAR-100 and CIFAR-10 datasets.
Specifically the model is at first trained over the CIFAR-100 dataset, a dataset containing 60.000 32x32 images (divded into 100 classes of 600 images each, and specifically of 500 training images and 100 test images each) representing each possible category in which the world entites can be grouped (there are actually 20 superclasses like aquatic mammals, fish, flowers, food containers,... and, for each superclass there are then some classes in which the images can be classified).
The obtained model is then used as the base of the training for our final model that is then trained with the CIFAR-10 dataset which is once again a dataset containing 60.000 32x32 images that are this time divided into 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) of 6.000 images each (5.000 for the training and 1.000 for testing).
The goal for our model is to creat a multiclass classificator used to classify each image provided by the users into one of the 10 classes provided by the CIFAR-10 dataset

2. Web Application
The web application acts as the front-end of our system: it can recieve any picture (of any dimensions or colors) as input and then it will display the prediction produced by our pre-trained model

3. Storage
The strage is the poin of contact of the parts of our system: it's a place in which the trained model is saved by the model training at the end of its task and in which the web application can retrieve the model in order to pass the input and wait for the prediction


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; IMPLEMENTATION
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Model Training Task
The implementation of the model has been made thanks to the Tensorflow and Keras library: we decided to use a Sequential Neural Network composed by different layers for recogninition and normalization; later on the first trained model has been used as first layer of our final model

2. Web Application
The framework used for the web application is Streamlit. Streamlit is a Python library used specifically to create web interfaces for machine learning model.
When first launched the application waits for the user to upload an image and then after submitting the input the application do some image pre-processing in order to make the image uploaded works with the model and then waits for the prediction made by the previously downloaded pre-trained model


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; STORAGE DEPLOYMENT
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. AWS S3 configuration
In order to use a bucket in which we will upload the trained model file we must first create it.

The parameters to be configured are the following:
- Name: model-bucket
- Region: us-east-1 (this should be good also into the Learner Lab)
- Access Control Lists: disabled
- Access Settings: enabled through the policy presented later
- Bucket Versioning: enabled to keep multiple version of the same file
- Tags and Encryption: disabled

The bucket must be accessible by the model script in writing mode and by the application in reading mode, so we define the following policy:
                                [POLICY]
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "PublicRead",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject",
                "s3:GetObjectVersion"
            ],
            "Resource": [
                "arn:aws:s3:::<BUCKET-NAME>/*"
            ]
        }
    ]
}
In this way the public access in read mode is permitted to anyone and, since the bucket will contain the trained model (which is not a secret file) there is no need to keep it hidden.

In order to let the bucket be accessible in writing mode by the script we will give the script the access and secret key of an IAM role that has the authorization to write to the S3 Bucket and so we should not enable a specific policy for that

2. FOLLOW THIS STEPS TO CREATE THE BUCKET
- Bucket Name: cloud-computing-model-bucket
- AWS Region: us-east-1
- Copy the settings from an existing bucket: optional (do not do anything and leave it as it is)
- Object Ownerships: check "ACL disabled"
- Block Public Access Settings for this Bucket:
    - Uncheck "Block ALL public access"
    - Check "Block public access to granted buckets and objects using new access control lists (ACLs)"
    - Check "Block public access to granted buckets and objects via any access control list (ACL)"
    - Check "I acknowledge that the current settings may make this bucket and the objects in it public."
- Multiple Version for the Bucket: check "Enable"
- Leave everything else as it is
- Create the Bucket
- From the dashboard:
    - Click on "Bucket"
    - Select the newly created bucket
    - Go on "Authorization"
    - Scroll down up until you find "Bucket Policy"
    - Click on "Modify"
    - Add the policy [POLICY] presented before by substituting the <BUCKET-NAME> with the name you gave to the bucket (you can also directly copy the bucket ARN presented by AWS)
    - Click on "Save Changes"


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; PREPARE THINGS TO WORK
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
0. KEYS TO ACCESS TO EVERYTHING CAN BE FOUND BY CLICKING "AWS Details" IN THE SANDBOX ACCESS PANEL UNDER THE AWS CLI SHOW BUTTON
1. Save the Secret Credentials to .aws/credentials file on your local machine (Remember to repeat this step everytime that the sandbox is started because the token expire)
2. Install AWS CLI (skip if present on local machine:
    - Go to "https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html" and follow the instruction for your OS


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; MODEL DEPLOYMENT
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Create a repository in ECR:
    - Go to ECR from the AWS Service Panel
    - Choose "Create Repository"
    - Select "Private" as "Visibility Option" (boh)
    - Choose a name for the repository (e.g. cloud_model)
    - Leave everything else as it is
    - Click on "Create Repository"
2. Push the image to the repository:
    - Go to "Repositories"
    - Select the wanted repository
    - Click on "Show Push Commands"
    - Copy the commands on your local shell where the AWS CLI is running and it's done
3. Create the EC2 instance:
    - From the AWS Service Panel go to EC2
    - Select "Instances"
    - From the dropdown menu "Start Instances" select "Start Instance"
    - Choose an instance name (e.g. Cloud Model)
    - Select "Amazon Linux" as AMI
    - Select "t2.large" as instance (not sure, maybe we can try something different when accessing to the true sandbox)
    - Choose the key-value pair "vockey" (default not sure if we can create another one but I don't thik so)
    - As for the "Network Settings" choose the "create a new security group" and leave everything as it is
    - Leave everything else as it is
    - Open "Advanced Details"
    - As for "Instance IAM Profile" choose "LabInstanceProfile"
    - Go to "user data" and add the following script [SCRIPT] to configure Docker on the instance:
                            [SCRIPT]
#!/bin/bash
sudo yum update -y
sudo yum install amazon-linux-extras
sudo amazon-linux-extras install docker -y
sudo service docker start
sudo usermod -a -G docker ec2-user
sudo systemctl enable docker
sudo gpasswd -a ec2-user docker
sudo grpck
sudo grpconv
newgrp docker
groups
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com
docker pull <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>:latest
docker run --rm <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>
                            [END SCRIPT]
    (AWS_ACCOUT_ID Lucia : 131920089270)
    (REPOSITORY_NAME Model : cloud_model)
    (REPOSITORY_NAME Web Application: cloud_webapp)
    - Click on "Start Instance"


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; WEB APPLICATION DEPLOYMENT
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
1. Create a repository in ECR:
    - Go to ECR from the AWS Service Panel
    - Choose "Create Repository"
    - Select "Private" as "Visibility Option" (boh)
    - Choose a name for the repository (e.g. cloud_model)
    - Leave everything else as it is
    - Click on "Create Repository"
2. Push the image to the repository:
    - Go to "Repositories"
    - Select the wanted repository
    - Click on "Show Push Commands"
    - Copy the commands on your local shell where the AWS CLI is running and it's done
3. Create the EC2 instance:
    - From the AWS Service Panel go to EC2
    - Select "Instances"
    - From the dropdown menu "Start Instances" select "Start Instance"
    - Choose an instance name (e.g. Cloud Model)
    - Select "Amazon Linux" as AMI
    - Select "t2.micro" as instance (not sure, maybe we can try something different when accessing to the true sandbox)
    - Choose the key-value pair "vockey" (default not sure if we can create another one but I don't thik so)
    - As for the "Network Settings" choose the "create a new security group"
    - Check the "Allow HTTP traffic from internet"
    - Click on Edit
    - Add a new security rule
    - Choose "Custom TCP"
    - As for the port type "8501"
    - Choose 0.0.0.0/0 to allow traffic from anywhere
    - Leave everything else as it is
    - Open "Advanced Details"
    - As for "Instance IAM Profile" choose "LabInstanceProfile"
    - Go to "user data" and add the following script [SCRIPT] to configure Docker on the instance:
                            [SCRIPT]
#!/bin/bash
sudo yum update -y
sudo yum install amazon-linux-extras
sudo amazon-linux-extras install docker -y
sudo service docker start
sudo usermod -a -G docker ec2-user
sudo systemctl enable docker
sudo gpasswd -a ec2-user docker
sudo grpck
sudo grpconv
newgrp docker
groups
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com
docker pull <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>:latest
docker run -dp 8501:8501 <AWS_ACCOUT_ID>.dkr.ecr.us-east-1.amazonaws.com/<REPOSITORY_NAME>
                            [END SCRIPT]
    (AWS_ACCOUT_ID Lucia : 131920089270)
    (REPOSITORY_NAME Web Application: cloud_webapp)
    - Click on "Start Instance"
    - Wait until the Status Check are passed
    - Now the web application is up and running!
    - To connect to the web application just copy the "Public IP Address" and then add :8501 to connect to the right port


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;; TESTS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

